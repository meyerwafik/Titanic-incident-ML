{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"./Data/train.csv\")\n",
    "test_data=pd.read_csv(\"./Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(data):\n",
    "    data[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].mean())\n",
    "    data[\"Embarked\"]=data[\"Embarked\"].fillna(\"X\")\n",
    "    data[\"SibSp\"]=data[\"SibSp\"].fillna(data[\"SibSp\"].median())\n",
    "    data[\"Parch\"]=data[\"Parch\"].fillna(data[\"Parch\"].median())\n",
    "    data[\"Fare\"]=data[\"Fare\"].fillna(data[\"Fare\"].mean())\n",
    "    data=data.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes the data frame and make some cleaning to it: <br/>\n",
    "1) Fill any null value in age with the mean age .<br/>\n",
    "2) Fill any  null in Embarked column with X.<br/>\n",
    "3) Fill the Parch and SibSp null rows with the median ( as it is not logic to be decimals) <br/>\n",
    "4) Fill any missing Fare (null) with the mean. <br/>\n",
    "5) Drop unneeded features: <br/>\n",
    "     a) Name and passenger ID doe not matter as they are different from a passenger to other passenger so no pattern could be got <br/>\n",
    "     b) Cabin has alot of null values so keeping it will result in inaccurate results. <br/>\n",
    "     c) Ticket values are different for all passengers, no pattern can be recognized. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId=test_data[\"PassengerId\"]\n",
    "train_data=CleanData(train_data)\n",
    "train_data_X=train_data.drop([\"Survived\"],axis=1)\n",
    "train_data_Y=train_data[\"Survived\"]\n",
    "test_data_X=CleanData(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1: Extract passenger ID column of test data to be used in submission <br/>\n",
    "Line 2: Clean the Training data <br/>\n",
    "Line 3: Get the training data without the label <br/>\n",
    "Line 4: Get the label of training data <br/>\n",
    "Line 5: Clean the test data <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=preprocessing.LabelEncoder()\n",
    "Coded_Features = ['Sex','Embarked']\n",
    "for col in Coded_Features:\n",
    "    train_data_X[col] = encoder.fit_transform(train_data_X[col])\n",
    "    test_data_X[col] = encoder.transform(test_data_X[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop on all features of letters to code them to a number using the fit transform for training data and transform for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_data_X, validate_data_X, train_data_Y, validate_data_Y = train_test_split(train_data_X, train_data_Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data 75% for training and 25% for validation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=2, random_state=42).fit(train_data_X, train_data_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boost classifier used as it combines many week models and the combination of results is made along running not at the end.\n",
    "It is a strong model but must be used carefully to prevent overfitting\n",
    "\n",
    "## Hyper tuning of Parameters:\n",
    "The learning rate: I tried many learning rates 1,0.01,0.05,0.1. <br/>\n",
    "   The 0.1 learning rate was the best as (1) has large oscillations so doesn't reach good result. <br/>\n",
    "   0.01 and 0.05 move slowly towards the optimal solution and does not reach it as it got stuck. <br/>\n",
    "The  n_estimators has to be large to prevent the overfitting but 1000 got lower results than 100 so 100 and used by trial and error <br/>\n",
    "The fit function was given the train data X and the label train data Y to build the model with these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8251121076233184\n"
     ]
    }
   ],
   "source": [
    "score=GBM.score(validate_data_X,validate_data_Y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the score when the validation data X is given and checking the predicted output with real output and get score percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_Y=GBM.predict(test_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test data using the model made with input test data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=pd.DataFrame({'PassengerId': PassengerId, 'Survived': test_data_Y})\n",
    "submit.to_csv('./Data/submission_prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the test results along with the passenger ID column extracted from test_data from above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
